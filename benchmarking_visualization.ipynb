{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d341e264",
   "metadata": {},
   "source": [
    "# Glacier Monitoring Benchmarking Visualization\n",
    "\n",
    "This notebook provides comprehensive benchmarking analysis for the glacier monitoring algorithm.\n",
    "\n",
    "## Test Structure:\n",
    "1. **Cell Processing Time Breakdown** - Pie diagram of processing phases\n",
    "2. **Cell Size Comparison** - Analysis of different grid sizes (1, 5, 10, 15, 20, 25 km)\n",
    "3. **Hardware Metrics** - RAM, CPU%, Network, Disk usage\n",
    "4. **Final Performance Metrics** - Time per kmÂ², Time per cell, Total glacier processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.figsize'] = [14, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Set your test run folder here\n",
    "# =============================================================================\n",
    "\n",
    "OUTPUT_DIR = Path('output')\n",
    "\n",
    "# For single test analysis, set the specific test folder\n",
    "SINGLE_TEST_DIR = OUTPUT_DIR / 'test_monitored'  # Change this to your test folder\n",
    "\n",
    "# For cell size comparison, define folders for each grid size\n",
    "# Format: {grid_size_km: 'folder_name'}\n",
    "CELL_SIZE_TESTS = {\n",
    "    # 1: 'test_1km',     # Uncomment and set folder names as you run tests\n",
    "    # 3: 'test_3km',\n",
    "    # 5: 'test_5km',\n",
    "    10: 'test_monitored',\n",
    "    # 12: 'test_12km',\n",
    "    # 15: 'test_15km',\n",
    "    # 18: 'test_18km',\n",
    "    # 20: 'test_20km',\n",
    "    # 25: 'test_25km',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b28b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(test_dir):\n",
    "    \"\"\"Load all data from a test directory.\"\"\"\n",
    "    test_path = Path(test_dir)\n",
    "    data = {\n",
    "        'name': test_path.name,\n",
    "        'path': test_path,\n",
    "        'statistics': None,\n",
    "        'monitoring': None,\n",
    "        'grid': None\n",
    "    }\n",
    "    \n",
    "    # Load statistics\n",
    "    stats_files = list(test_path.glob('statistics_*.json'))\n",
    "    if stats_files:\n",
    "        with open(stats_files[0], 'r') as f:\n",
    "            data['statistics'] = json.load(f)\n",
    "    \n",
    "    # Load monitoring data\n",
    "    monitoring_files = list(test_path.glob('proxmox_monitoring_*.json'))\n",
    "    if monitoring_files:\n",
    "        with open(monitoring_files[0], 'r') as f:\n",
    "            data['monitoring'] = json.load(f)\n",
    "    \n",
    "    # Load grid\n",
    "    grid_files = list(test_path.glob('processed_grid_*.geojson'))\n",
    "    if grid_files:\n",
    "        data['grid'] = gpd.read_file(grid_files[0])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load single test data\n",
    "test_data = load_test_data(SINGLE_TEST_DIR)\n",
    "print(f\"Loaded test: {test_data['name']}\")\n",
    "print(f\"  Statistics: {'âœ…' if test_data['statistics'] else 'âŒ'}\")\n",
    "print(f\"  Monitoring: {'âœ…' if test_data['monitoring'] else 'âŒ'}\")\n",
    "print(f\"  Grid: {'âœ…' if test_data['grid'] is not None else 'âŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7472e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Cell Processing Time Breakdown (Pie Diagram)\n",
    "\n",
    "Shows the time distribution across different processing phases:\n",
    "- STAC Query\n",
    "- Zarr Loading\n",
    "- NDSI Computation\n",
    "- Tile Saving\n",
    "- Spatial Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data['statistics'] and 'cell_timing' in test_data['statistics'].get('results', {}):\n",
    "    timing = test_data['statistics']['results']['cell_timing']\n",
    "    time_dist = timing.get('time_distribution_percent', {})\n",
    "    total_times = timing.get('total_times', {})\n",
    "    \n",
    "    # Prepare data for pie chart\n",
    "    labels = ['STAC Query', 'Zarr Loading', 'NDSI Computation', 'Tile Saving', 'Spatial Expansion']\n",
    "    sizes = [\n",
    "        time_dist.get('stac_query', 0),\n",
    "        time_dist.get('zarr_load', 0),\n",
    "        time_dist.get('ndsi_compute', 0),\n",
    "        time_dist.get('tile_save', 0),\n",
    "        time_dist.get('spatial_expansion', 0)\n",
    "    ]\n",
    "    \n",
    "    # Filter out zero values for cleaner pie chart\n",
    "    filtered_labels = []\n",
    "    filtered_sizes = []\n",
    "    for label, size in zip(labels, sizes):\n",
    "        if size > 0.1:  # Only show segments > 0.1%\n",
    "            filtered_labels.append(label)\n",
    "            filtered_sizes.append(size)\n",
    "    \n",
    "    # Colors for each segment\n",
    "    colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#ffeaa7']\n",
    "    filtered_colors = colors[:len(filtered_labels)]\n",
    "    \n",
    "    # Create pie chart\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Pie chart\n",
    "    wedges, texts, autotexts = ax1.pie(\n",
    "        filtered_sizes, \n",
    "        labels=filtered_labels,\n",
    "        autopct='%1.1f%%',\n",
    "        colors=filtered_colors,\n",
    "        explode=[0.02] * len(filtered_sizes),\n",
    "        shadow=True,\n",
    "        startangle=90\n",
    "    )\n",
    "    ax1.set_title('Cell Processing Time Breakdown', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Make percentage labels more visible\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "    \n",
    "    # Bar chart with absolute times\n",
    "    bar_labels = ['STAC Query', 'Zarr Load', 'NDSI Compute', 'Tile Save', 'Expansion']\n",
    "    bar_values = [\n",
    "        total_times.get('stac_query_seconds', 0),\n",
    "        total_times.get('zarr_load_seconds', 0),\n",
    "        total_times.get('ndsi_compute_seconds', 0),\n",
    "        total_times.get('tile_save_seconds', 0),\n",
    "        total_times.get('spatial_expansion_seconds', 0)\n",
    "    ]\n",
    "    \n",
    "    bars = ax2.bar(bar_labels, bar_values, color=colors, edgecolor='white', linewidth=1.5)\n",
    "    ax2.set_ylabel('Time (seconds)', fontsize=12)\n",
    "    ax2.set_title('Absolute Processing Times', fontsize=14, fontweight='bold')\n",
    "    ax2.tick_params(axis='x', rotation=30)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, bar_values):\n",
    "        if val > 0:\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                    f'{val:.1f}s', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print text summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CELL PROCESSING TIME BREAKDOWN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nTime distribution:\")\n",
    "    print(f\"  STAC query:           {time_dist.get('stac_query', 0):>6.1f}%\")\n",
    "    print(f\"  Zarr loading:         {time_dist.get('zarr_load', 0):>6.1f}%\")\n",
    "    print(f\"  NDSI computation:     {time_dist.get('ndsi_compute', 0):>6.1f}%\")\n",
    "    print(f\"  Tile saving:          {time_dist.get('tile_save', 0):>6.1f}%\")\n",
    "    print(f\"  Spatial expansion:    {time_dist.get('spatial_expansion', 0):>6.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Total cell time:      {total_times.get('total_cell_processing_seconds', 0):.1f}s\")\n",
    "else:\n",
    "    print(\"âŒ No cell timing data available in statistics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d49ce5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Cell Size Comparison\n",
    "\n",
    "Compare processing performance across different grid cell sizes:\n",
    "- 1 km, 5 km, 10 km, 15 km, 20 km, 25 km\n",
    "\n",
    "Shows:\n",
    "- Processing time\n",
    "- Number of cells\n",
    "- Result grid visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all cell size test data\n",
    "cell_size_data = {}\n",
    "\n",
    "for size_km, folder_name in CELL_SIZE_TESTS.items():\n",
    "    folder_path = OUTPUT_DIR / folder_name\n",
    "    if folder_path.exists():\n",
    "        cell_size_data[size_km] = load_test_data(folder_path)\n",
    "        print(f\"âœ… Loaded {size_km}km test from '{folder_name}'\")\n",
    "    else:\n",
    "        print(f\"âŒ Folder not found: {folder_path}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(cell_size_data)} cell size tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(cell_size_data) >= 1:\n",
    "    # Prepare comparison data\n",
    "    comparison = []\n",
    "    for size_km, data in sorted(cell_size_data.items()):\n",
    "        if data['statistics']:\n",
    "            stats = data['statistics']\n",
    "            config = stats.get('configuration', {})\n",
    "            results = stats.get('results', {})\n",
    "            timing = results.get('cell_timing', {})\n",
    "            \n",
    "            # Calculate snow_percentage null rate from grid\n",
    "            null_rate = 0.0\n",
    "            if data['grid'] is not None:\n",
    "                grid = data['grid']\n",
    "                processed = grid[grid['is_processed'] == True]\n",
    "                if len(processed) > 0 and 'snow_percentage' in processed.columns:\n",
    "                    null_count = processed['snow_percentage'].isna().sum()\n",
    "                    null_rate = 100 * null_count / len(processed)\n",
    "            \n",
    "            comparison.append({\n",
    "                'Grid Size (km)': size_km,\n",
    "                'Grid Size (m)': config.get('grid_size', size_km * 1000),\n",
    "                'Cells Processed': results.get('total_cells_processed', 0),\n",
    "                'Total Time (s)': results.get('processing_time_seconds', 0),\n",
    "                'Avg Time/Cell (s)': timing.get('average_times_per_cell', {}).get('total_seconds', 0),\n",
    "                'Snow/Ice kmÂ²': results.get('snow_ice_coverage_km2', 0),\n",
    "                'Snow %': results.get('snow_ice_percentage', 0),\n",
    "                'Null Rate (%)': null_rate,\n",
    "            })\n",
    "    \n",
    "    if comparison:\n",
    "        comp_df = pd.DataFrame(comparison)\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"CELL SIZE COMPARISON\")\n",
    "        print(\"=\" * 80)\n",
    "        display(comp_df)\n",
    "        \n",
    "        # Visualization\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        \n",
    "        sizes = comp_df['Grid Size (km)'].values\n",
    "        colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(sizes)))\n",
    "        \n",
    "        # Total Processing Time\n",
    "        ax1 = axes[0, 0]\n",
    "        bars1 = ax1.bar([f\"{s}km\" for s in sizes], comp_df['Total Time (s)'], color=colors, edgecolor='white')\n",
    "        ax1.set_ylabel('Time (seconds)')\n",
    "        ax1.set_title('Total Processing Time by Grid Size', fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "        for bar, val in zip(bars1, comp_df['Total Time (s)']):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                    f'{val:.0f}s', ha='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Number of Cells\n",
    "        ax2 = axes[0, 1]\n",
    "        bars2 = ax2.bar([f\"{s}km\" for s in sizes], comp_df['Cells Processed'], color=colors, edgecolor='white')\n",
    "        ax2.set_ylabel('Number of Cells')\n",
    "        ax2.set_title('Cells Processed by Grid Size', fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        for bar, val in zip(bars2, comp_df['Cells Processed']):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "                    str(int(val)), ha='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Time per Cell\n",
    "        ax3 = axes[0, 2]\n",
    "        bars3 = ax3.bar([f\"{s}km\" for s in sizes], comp_df['Avg Time/Cell (s)'], color=colors, edgecolor='white')\n",
    "        ax3.set_ylabel('Time (seconds)')\n",
    "        ax3.set_title('Average Time per Cell', fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        for bar, val in zip(bars3, comp_df['Avg Time/Cell (s)']):\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                    f'{val:.1f}s', ha='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Snow Coverage\n",
    "        ax4 = axes[1, 0]\n",
    "        bars4 = ax4.bar([f\"{s}km\" for s in sizes], comp_df['Snow/Ice kmÂ²'], color=colors, edgecolor='white')\n",
    "        ax4.set_ylabel('Coverage (kmÂ²)')\n",
    "        ax4.set_title('Snow/Ice Coverage Detected', fontweight='bold')\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        for bar, val in zip(bars4, comp_df['Snow/Ice kmÂ²']):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                    f'{val:.1f}', ha='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Snow Percentage\n",
    "        ax5 = axes[1, 1]\n",
    "        bars5 = ax5.bar([f\"{s}km\" for s in sizes], comp_df['Snow %'], color=colors, edgecolor='white')\n",
    "        ax5.set_ylabel('Snow/Ice (%)')\n",
    "        ax5.set_title('Snow/Ice Percentage in Valid Area', fontweight='bold')\n",
    "        ax5.grid(True, alpha=0.3, axis='y')\n",
    "        for bar, val in zip(bars5, comp_df['Snow %']):\n",
    "            ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                    f'{val:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Null Rate (Data Quality)\n",
    "        ax6 = axes[1, 2]\n",
    "        null_colors = ['#ff6b6b' if v > 10 else '#ffeaa7' if v > 5 else '#96ceb4' for v in comp_df['Null Rate (%)']]\n",
    "        bars6 = ax6.bar([f\"{s}km\" for s in sizes], comp_df['Null Rate (%)'], color=null_colors, edgecolor='white')\n",
    "        ax6.set_ylabel('Null Rate (%)')\n",
    "        ax6.set_title('Snow% Null Rate (Data Quality)', fontweight='bold')\n",
    "        ax6.grid(True, alpha=0.3, axis='y')\n",
    "        ax6.axhline(y=5, color='#ffeaa7', linestyle='--', alpha=0.7, label='Warning (5%)')\n",
    "        ax6.axhline(y=10, color='#ff6b6b', linestyle='--', alpha=0.7, label='Critical (10%)')\n",
    "        ax6.legend(loc='upper right', fontsize=8)\n",
    "        for bar, val in zip(bars6, comp_df['Null Rate (%)']):\n",
    "            ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "                    f'{val:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        plt.suptitle('Grid Cell Size Comparison', fontsize=16, fontweight='bold', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Not enough cell size test data for comparison.\")\n",
    "    print(\"Run tests with different grid sizes and update CELL_SIZE_TESTS configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00558d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize result grids for each cell size\n",
    "grids_to_show = [(size, data) for size, data in sorted(cell_size_data.items()) if data['grid'] is not None]\n",
    "\n",
    "if grids_to_show:\n",
    "    n_grids = len(grids_to_show)\n",
    "    cols = min(3, n_grids)\n",
    "    rows = (n_grids + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    if n_grids == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes if isinstance(axes, np.ndarray) else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for idx, (size_km, data) in enumerate(grids_to_show):\n",
    "        ax = axes[idx]\n",
    "        grid = data['grid']\n",
    "        \n",
    "        # Plot grid with snow percentage coloring\n",
    "        processed = grid[grid['is_processed'] == True]\n",
    "        if 'snow_percentage' in processed.columns and not processed['snow_percentage'].isna().all():\n",
    "            processed.plot(column='snow_percentage', ax=ax, legend=True, \n",
    "                          cmap='Blues', edgecolor='white', linewidth=0.5,\n",
    "                          legend_kwds={'label': 'Snow %', 'shrink': 0.8})\n",
    "        else:\n",
    "            processed.plot(ax=ax, color='#4ecdc4', edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        ax.set_title(f'{size_km} km Grid ({len(processed)} cells)', fontweight='bold')\n",
    "        ax.set_xlabel('X (m)')\n",
    "        ax.set_ylabel('Y (m)')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(grids_to_show), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Result Grids by Cell Size', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No grid data available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64181f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Hardware Metrics\n",
    "\n",
    "Analyze hardware resource usage:\n",
    "- RAM Usage\n",
    "- CPU Utilization (%)\n",
    "- Network Transfer\n",
    "- Disk I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed324be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data['monitoring']:\n",
    "    mon = test_data['monitoring']\n",
    "    samples = pd.DataFrame(mon['samples'])\n",
    "    samples['elapsed_seconds'] = samples['time'] - samples['time'].iloc[0]\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    samples['mem_gb'] = samples['mem'] / (1024**3)\n",
    "    samples['maxmem_gb'] = samples['maxmem'] / (1024**3)\n",
    "    samples['netin_rate'] = samples['netin'].diff() / samples['time'].diff()\n",
    "    samples['netin_mbps'] = samples['netin_rate'] * 8 / 1e6\n",
    "    samples['diskread_rate'] = samples['diskread'].diff() / samples['time'].diff() / 1e6\n",
    "    samples['diskwrite_rate'] = samples['diskwrite'].diff() / samples['time'].diff() / 1e6\n",
    "    samples = samples.fillna(0)\n",
    "    \n",
    "    # Create 2x2 hardware metrics dashboard\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # RAM Usage\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.fill_between(samples['elapsed_seconds'], samples['mem_gb'], alpha=0.4, color='#6b8aff')\n",
    "    ax1.plot(samples['elapsed_seconds'], samples['mem_gb'], color='#6b8aff', linewidth=1.5)\n",
    "    ax1.axhline(y=samples['mem_gb'].mean(), color='#ff6b6b', linestyle='--', \n",
    "                label=f\"Avg: {samples['mem_gb'].mean():.2f} GB\")\n",
    "    ax1.axhline(y=samples['maxmem_gb'].iloc[0], color='#ffaa00', linestyle=':', alpha=0.7,\n",
    "                label=f\"Max Available: {samples['maxmem_gb'].iloc[0]:.1f} GB\")\n",
    "    ax1.set_ylabel('RAM Usage (GB)', fontsize=12)\n",
    "    ax1.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax1.set_title('RAM Usage', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, samples['maxmem_gb'].iloc[0] * 1.1)\n",
    "    \n",
    "    # CPU %\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.fill_between(samples['elapsed_seconds'], samples['cpu_percent'], alpha=0.4, color='#00ff88')\n",
    "    ax2.plot(samples['elapsed_seconds'], samples['cpu_percent'], color='#00ff88', linewidth=1.5)\n",
    "    ax2.axhline(y=mon['cpu_stats']['avg_percent'], color='#ff6b6b', linestyle='--',\n",
    "                label=f\"Avg: {mon['cpu_stats']['avg_percent']:.1f}%\")\n",
    "    ax2.set_ylabel('CPU Usage (%)', fontsize=12)\n",
    "    ax2.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax2.set_title('CPU Utilization', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, max(100, samples['cpu_percent'].max() * 1.1))\n",
    "    \n",
    "    # Network\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.fill_between(samples['elapsed_seconds'], samples['netin_mbps'], alpha=0.4, color='#4ecdc4')\n",
    "    ax3.plot(samples['elapsed_seconds'], samples['netin_mbps'], color='#4ecdc4', linewidth=1)\n",
    "    ax3.axhline(y=mon['network_transfer']['avg_speed_mbps_in'], color='#ff6b6b', linestyle='--',\n",
    "                label=f\"Avg: {mon['network_transfer']['avg_speed_mbps_in']:.1f} Mbps\")\n",
    "    ax3.set_ylabel('Network Speed (Mbps)', fontsize=12)\n",
    "    ax3.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax3.set_title('Network Download Speed', fontsize=14, fontweight='bold')\n",
    "    ax3.legend(loc='upper right')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Disk I/O\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.fill_between(samples['elapsed_seconds'], samples['diskread_rate'], alpha=0.4, color='#96ceb4', label='Read')\n",
    "    ax4.fill_between(samples['elapsed_seconds'], samples['diskwrite_rate'], alpha=0.4, color='#ffeaa7', label='Write')\n",
    "    ax4.plot(samples['elapsed_seconds'], samples['diskread_rate'], color='#96ceb4', linewidth=1)\n",
    "    ax4.plot(samples['elapsed_seconds'], samples['diskwrite_rate'], color='#ffeaa7', linewidth=1)\n",
    "    ax4.set_ylabel('Disk I/O (MB/s)', fontsize=12)\n",
    "    ax4.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax4.set_title('Disk I/O', fontsize=14, fontweight='bold')\n",
    "    ax4.legend(loc='upper right')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Hardware Resource Usage', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"HARDWARE METRICS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nðŸ’¾ RAM:\")\n",
    "    print(f\"   Min:  {samples['mem_gb'].min():.2f} GB\")\n",
    "    print(f\"   Max:  {samples['mem_gb'].max():.2f} GB\")\n",
    "    print(f\"   Avg:  {samples['mem_gb'].mean():.2f} GB\")\n",
    "    print(f\"   Total: {samples['maxmem_gb'].iloc[0]:.1f} GB\")\n",
    "    \n",
    "    print(f\"\\nðŸ–¥ï¸ CPU:\")\n",
    "    print(f\"   Min:  {mon['cpu_stats']['min_percent']:.1f}%\")\n",
    "    print(f\"   Max:  {mon['cpu_stats']['max_percent']:.1f}%\")\n",
    "    print(f\"   Avg:  {mon['cpu_stats']['avg_percent']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nðŸŒ Network:\")\n",
    "    print(f\"   Downloaded: {mon['network_transfer']['mb_in']:.1f} MB\")\n",
    "    print(f\"   Avg Speed:  {mon['network_transfer']['avg_speed_mbps_in']:.1f} Mbps\")\n",
    "    print(f\"   Peak Speed: {samples['netin_mbps'].max():.1f} Mbps\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¿ Disk:\")\n",
    "    print(f\"   Read:    {mon['disk_io']['mb_read']:.1f} MB\")\n",
    "    print(f\"   Written: {mon['disk_io']['mb_written']:.1f} MB\")\n",
    "else:\n",
    "    print(\"âŒ No monitoring data available. Run with --proxmox flag to collect hardware metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342373c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Final Performance Metrics (Bar Charts)\n",
    "\n",
    "Key performance indicators:\n",
    "- **Time per kmÂ²** - Processing efficiency\n",
    "- **Time per Cell (avg)** - Cell processing speed\n",
    "- **Total Glacier Area Processing Time** - End-to-end performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1744fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final metrics from all available tests\n",
    "final_metrics = []\n",
    "\n",
    "for size_km, data in sorted(cell_size_data.items()):\n",
    "    if data['statistics']:\n",
    "        stats = data['statistics']\n",
    "        results = stats.get('results', {})\n",
    "        timing = results.get('cell_timing', {})\n",
    "        \n",
    "        total_time = results.get('processing_time_seconds', 0)\n",
    "        cells = results.get('total_cells_processed', 0)\n",
    "        coverage_km2 = results.get('snow_ice_coverage_km2', 0)\n",
    "        valid_area_km2 = results.get('total_valid_area_km2', 0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        time_per_km2 = total_time / coverage_km2 if coverage_km2 > 0 else 0\n",
    "        time_per_cell = timing.get('average_times_per_cell', {}).get('total_seconds', \n",
    "                                   total_time / cells if cells > 0 else 0)\n",
    "        \n",
    "        # Calculate null rate from grid\n",
    "        null_rate = 0.0\n",
    "        null_count = 0\n",
    "        total_processed = 0\n",
    "        if data['grid'] is not None:\n",
    "            grid = data['grid']\n",
    "            processed = grid[grid['is_processed'] == True]\n",
    "            total_processed = len(processed)\n",
    "            if total_processed > 0 and 'snow_percentage' in processed.columns:\n",
    "                null_count = int(processed['snow_percentage'].isna().sum())\n",
    "                null_rate = 100 * null_count / total_processed\n",
    "        \n",
    "        final_metrics.append({\n",
    "            'Grid Size': f'{size_km} km',\n",
    "            'Grid Size (km)': size_km,\n",
    "            'Time per kmÂ² (s)': time_per_km2,\n",
    "            'Avg Time per Cell (s)': time_per_cell,\n",
    "            'Total Processing Time (s)': total_time,\n",
    "            'Glacier Area (kmÂ²)': coverage_km2,\n",
    "            'Cells Processed': cells,\n",
    "            'Null Count': null_count,\n",
    "            'Null Rate (%)': null_rate\n",
    "        })\n",
    "\n",
    "if final_metrics:\n",
    "    metrics_df = pd.DataFrame(final_metrics)\n",
    "    \n",
    "    # Create bar charts\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    sizes = metrics_df['Grid Size'].values\n",
    "    colors = plt.cm.plasma(np.linspace(0.2, 0.8, len(sizes)))\n",
    "    \n",
    "    # Time per kmÂ²\n",
    "    ax1 = axes[0, 0]\n",
    "    bars1 = ax1.bar(sizes, metrics_df['Time per kmÂ² (s)'], color=colors, edgecolor='white', linewidth=2)\n",
    "    ax1.set_ylabel('Time (seconds)', fontsize=12)\n",
    "    ax1.set_title('Processing Time per kmÂ²', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    for bar, val in zip(bars1, metrics_df['Time per kmÂ² (s)']):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{val:.2f}s', ha='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Avg Time per Cell\n",
    "    ax2 = axes[0, 1]\n",
    "    bars2 = ax2.bar(sizes, metrics_df['Avg Time per Cell (s)'], color=colors, edgecolor='white', linewidth=2)\n",
    "    ax2.set_ylabel('Time (seconds)', fontsize=12)\n",
    "    ax2.set_title('Average Processing Time per Cell', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    for bar, val in zip(bars2, metrics_df['Avg Time per Cell (s)']):\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                f'{val:.1f}s', ha='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Total Processing Time for Glacier Area\n",
    "    ax3 = axes[1, 0]\n",
    "    bars3 = ax3.bar(sizes, metrics_df['Total Processing Time (s)'], color=colors, edgecolor='white', linewidth=2)\n",
    "    ax3.set_ylabel('Time (seconds)', fontsize=12)\n",
    "    ax3.set_title('Total Glacier Area Processing Time', fontsize=14, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    for bar, val in zip(bars3, metrics_df['Total Processing Time (s)']):\n",
    "        mins = int(val // 60)\n",
    "        secs = int(val % 60)\n",
    "        label = f'{mins}m {secs}s' if mins > 0 else f'{val:.0f}s'\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                label, ha='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Null Rate (Data Quality)\n",
    "    ax4 = axes[1, 1]\n",
    "    null_colors = ['#ff6b6b' if v > 10 else '#ffeaa7' if v > 5 else '#96ceb4' for v in metrics_df['Null Rate (%)']]\n",
    "    bars4 = ax4.bar(sizes, metrics_df['Null Rate (%)'], color=null_colors, edgecolor='white', linewidth=2)\n",
    "    ax4.set_ylabel('Null Rate (%)', fontsize=12)\n",
    "    ax4.set_title('Snow% Null Rate (Data Quality)', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    ax4.axhline(y=5, color='#ffeaa7', linestyle='--', alpha=0.7, label='Warning (5%)')\n",
    "    ax4.axhline(y=10, color='#ff6b6b', linestyle='--', alpha=0.7, label='Critical (10%)')\n",
    "    ax4.legend(loc='upper right')\n",
    "    for bar, val, cnt in zip(bars4, metrics_df['Null Rate (%)'], metrics_df['Null Count']):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "                f'{val:.1f}%\\n({int(cnt)} cells)', ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Final Performance Metrics', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL PERFORMANCE METRICS\")\n",
    "    print(\"=\" * 80)\n",
    "    display(metrics_df[['Grid Size', 'Time per kmÂ² (s)', 'Avg Time per Cell (s)', \n",
    "                        'Total Processing Time (s)', 'Glacier Area (kmÂ²)', 'Cells Processed',\n",
    "                        'Null Count', 'Null Rate (%)']])\n",
    "else:\n",
    "    print(\"âŒ No statistics data available for final metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2665dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined efficiency visualization\n",
    "if final_metrics and len(final_metrics) > 1:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(sizes))\n",
    "    width = 0.25\n",
    "    \n",
    "    # Normalize values for comparison (scale to 0-100)\n",
    "    max_time_km2 = max(m['Time per kmÂ² (s)'] for m in final_metrics)\n",
    "    max_time_cell = max(m['Avg Time per Cell (s)'] for m in final_metrics)\n",
    "    max_total = max(m['Total Processing Time (s)'] for m in final_metrics)\n",
    "    \n",
    "    time_km2_norm = [100 * m['Time per kmÂ² (s)'] / max_time_km2 for m in final_metrics]\n",
    "    time_cell_norm = [100 * m['Avg Time per Cell (s)'] / max_time_cell for m in final_metrics]\n",
    "    total_norm = [100 * m['Total Processing Time (s)'] / max_total for m in final_metrics]\n",
    "    \n",
    "    bars1 = ax.bar(x - width, time_km2_norm, width, label='Time/kmÂ² (normalized)', color='#ff6b6b', alpha=0.8)\n",
    "    bars2 = ax.bar(x, time_cell_norm, width, label='Time/Cell (normalized)', color='#4ecdc4', alpha=0.8)\n",
    "    bars3 = ax.bar(x + width, total_norm, width, label='Total Time (normalized)', color='#45b7d1', alpha=0.8)\n",
    "    \n",
    "    ax.set_ylabel('Normalized Value (% of max)', fontsize=12)\n",
    "    ax.set_xlabel('Grid Size', fontsize=12)\n",
    "    ax.set_title('Performance Comparison Across Grid Sizes (Normalized)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(sizes)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "elif final_metrics:\n",
    "    print(\"â„¹ï¸ Only one grid size available. Run more tests to enable comparison chart.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db0730",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4dcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BENCHMARKING SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if test_data['statistics']:\n",
    "    stats = test_data['statistics']\n",
    "    results = stats.get('results', {})\n",
    "    config = stats.get('configuration', {})\n",
    "    timing = results.get('cell_timing', {})\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Test Configuration:\")\n",
    "    print(f\"   Grid Size: {config.get('grid_size', 'N/A')/1000:.0f} km\")\n",
    "    print(f\"   Date Range: {config.get('date_start')} to {config.get('date_end')}\")\n",
    "    print(f\"   NDSI Threshold: {config.get('ndsi_threshold')}\")\n",
    "    print(f\"   Snow Expansion Threshold: {config.get('snow_percentage_threshold')*100:.0f}%\")\n",
    "    print(f\"   Low Memory Mode: {config.get('low_memory', False)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Processing Results:\")\n",
    "    print(f\"   Cells Processed: {results.get('total_cells_processed', 'N/A')}\")\n",
    "    print(f\"   Iterations: {results.get('iterations', 'N/A')}\")\n",
    "    print(f\"   Total Time: {results.get('processing_time_formatted', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”ï¸ Coverage Results:\")\n",
    "    print(f\"   Snow/Ice Coverage: {results.get('snow_ice_coverage_km2', 0):.2f} kmÂ²\")\n",
    "    print(f\"   Valid Area Analyzed: {results.get('total_valid_area_km2', 0):.2f} kmÂ²\")\n",
    "    print(f\"   Snow/Ice Percentage: {results.get('snow_ice_percentage', 0):.1f}%\")\n",
    "    \n",
    "    # Calculate null rate from grid\n",
    "    if test_data['grid'] is not None:\n",
    "        grid = test_data['grid']\n",
    "        processed = grid[grid['is_processed'] == True]\n",
    "        if len(processed) > 0 and 'snow_percentage' in processed.columns:\n",
    "            null_count = int(processed['snow_percentage'].isna().sum())\n",
    "            null_rate = 100 * null_count / len(processed)\n",
    "            print(f\"\\nâš ï¸ Data Quality:\")\n",
    "            print(f\"   Cells with null snow%: {null_count} / {len(processed)}\")\n",
    "            print(f\"   Null Rate: {null_rate:.2f}%\")\n",
    "            if null_rate > 10:\n",
    "                print(f\"   Status: âŒ CRITICAL - Many cells missing data\")\n",
    "            elif null_rate > 5:\n",
    "                print(f\"   Status: âš ï¸ WARNING - Some cells missing data\")\n",
    "            else:\n",
    "                print(f\"   Status: âœ… GOOD - Most cells have valid data\")\n",
    "    \n",
    "    print(f\"\\nâ±ï¸ Time Breakdown:\")\n",
    "    time_dist = timing.get('time_distribution_percent', {})\n",
    "    print(f\"   STAC Query:       {time_dist.get('stac_query', 0):>5.1f}%\")\n",
    "    print(f\"   Zarr Loading:     {time_dist.get('zarr_load', 0):>5.1f}%\")\n",
    "    print(f\"   NDSI Computation: {time_dist.get('ndsi_compute', 0):>5.1f}%\")\n",
    "    print(f\"   Tile Saving:      {time_dist.get('tile_save', 0):>5.1f}%\")\n",
    "    print(f\"   Expansion:        {time_dist.get('spatial_expansion', 0):>5.1f}%\")\n",
    "\n",
    "if test_data['monitoring']:\n",
    "    mon = test_data['monitoring']\n",
    "    print(f\"\\nðŸ’» Hardware Usage:\")\n",
    "    print(f\"   CPU Avg: {mon['cpu_stats']['avg_percent']:.1f}% (Max: {mon['cpu_stats']['max_percent']:.1f}%)\")\n",
    "    samples_df = pd.DataFrame(mon['samples'])\n",
    "    mem_avg = samples_df['mem'].mean() / (1024**3)\n",
    "    mem_max = samples_df['mem'].max() / (1024**3)\n",
    "    print(f\"   RAM Avg: {mem_avg:.2f} GB (Max: {mem_max:.2f} GB)\")\n",
    "    print(f\"   Network: {mon['network_transfer']['mb_in']:.1f} MB downloaded\")\n",
    "    print(f\"   Disk: {mon['disk_io']['mb_written']:.1f} MB written\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
