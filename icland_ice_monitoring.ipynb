{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iceland Snow and Ice Monitoring\n",
    "\n",
    "This notebook implements a workflow for monitoring snow and ice in Iceland using Sentinel-2 data via the EOPF Zarr format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "from xcube.core.store import new_data_store\n",
    "from xcube_eopf.utils import reproject_bbox\n",
    "from shapely.geometry import box\n",
    "import shapely.geometry\n",
    "\n",
    "# Initialize Data Store\n",
    "store = new_data_store(\"eopf-zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeds\n",
    "Load the glacier seeds (points) and define the Area of Interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load seeds\n",
    "seeds_gdf = gpd.read_file(\"data/Iceland_Seeds.geojson\")\n",
    "\n",
    "# Reproject to WGS84 for search\n",
    "seeds_gdf = seeds_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Create a buffer around seeds (approx 5km for 10x10km tile) or just use bounds\n",
    "# For the native algorithm, we want scenes covering these seeds.\n",
    "total_bounds = seeds_gdf.total_bounds # [minx, miny, maxx, maxy]\n",
    "print(f\"Total Bounds (EPSG:4326): {total_bounds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel Native Algorithm\n",
    "\n",
    "This algorithm simulates a file-based workflow by processing full Sentinel-2 scenes (Sentinel-2 L2A) retrieved from the EOPF Zarr store. \n",
    "It avoids tile-based optimization and instead loads the full scene extent to compute NDSI and classify snow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scene_native(scene_id, store, threshold=0.42):\n",
    "    \"\"\"\n",
    "    Process a single Sentinel-2 scene using the Native approach.\n",
    "    Loads the full scene, computes NDSI, and classifies snow.\n",
    "    \"\"\"\n",
    "    print(f\"Processing scene: {scene_id}\", flush=True)\n",
    "    \n",
    "    # Open the dataset using the scene ID directly\n",
    "    # We do not provide a bbox to open_data to ensure we get the full scene extent available in the store\n",
    "    # Note: If the store requires a bbox for 'sentinel-2-l2a', we might need to fetch the scene metadata first.\n",
    "    # Assuming 'scene_id' can be passed as data_id or we filter by it.\n",
    "    \n",
    "    # Try opening as a specific product if supported, or filter collection\n",
    "    try:\n",
    "        # Attempt to open the specific product. \n",
    "        # In some EOPF stores, the data_id is the product ID. \n",
    "        ds = store.open_data(data_id=scene_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not open {scene_id} directly: {e}\", flush=True)\n",
    "        return None\n",
    "\n",
    "    # Mask valid data using SCL (Scene Classification Layer)\n",
    "    # SCL: 8=Dark, 9=Cloud Shadows, 3=Cloud Shadows (usually 3 is cloud shadow, 8,9 are clouds/cirrus)\n",
    "    # Sentinel-2 SCL: 3=Cloud Shadows, 8=Cloud Medium Probability, 9=Cloud High Probability\n",
    "    if \"scl\" in ds:\n",
    "        valid_mask = ~ds[\"scl\"].isin([3, 8, 9])\n",
    "        ds_valid = ds.where(valid_mask)\n",
    "    else:\n",
    "        print(\"SCL layer not found, skipping cloud masking.\", flush=True)\n",
    "        ds_valid = ds\n",
    "\n",
    "    # NDSI Computation\n",
    "    # NDSI = (Green - SWIR) / (Green + SWIR)\n",
    "    # Bands: Green=B03, SWIR=B11\n",
    "    if \"b03\" in ds_valid and \"b11\" in ds_valid:\n",
    "        green = ds_valid[\"b03\"]\n",
    "        swir = ds_valid[\"b11\"]\n",
    "        \n",
    "        # Load data into memory to simulate \"downloading the whole file\"\n",
    "        # This forces retrieval of all chunks for these bands\n",
    "        green.load()\n",
    "        swir.load()\n",
    "        \n",
    "        ndsi = (green - swir) / (green + swir)\n",
    "        snow_map = ndsi > threshold\n",
    "        \n",
    "        # Calculate Snow Cover Percentage\n",
    "        # Count valid pixels\n",
    "        valid_count = valid_mask.sum().compute()\n",
    "        snow_count = snow_map.where(valid_mask).sum().compute()\n",
    "        \n",
    "        if valid_count > 0:\n",
    "            snow_pct = (snow_count / valid_count) * 100\n",
    "        else:\n",
    "            snow_pct = 0\n",
    "            \n",
    "        print(f\"  Snow Cover: {snow_pct:.2f}%\", flush=True)\n",
    "        return {\n",
    "            \"scene_id\": scene_id,\n",
    "            \"snow_pct\": snow_pct,\n",
    "            \"snow_area_px\": snow_count.item(),\n",
    "            \"snow_map\": snow_map # Keep in memory or save if needed\n",
    "        }\n",
    "    else:\n",
    "        print(\"  Required bands (B03, B11) not found.\", flush=True)\n",
    "        return None\n",
    "\n",
    "def sentinel_native_algorithm(seeds_gdf, time_range, store):\n",
    "    \"\"\"\n",
    "    Main function for the Native Algorithm.\n",
    "    1. Search for scenes covering the seeds.\n",
    "    2. Process each scene (load full, compute NDSI).\n",
    "    3. If snow > 30%, (conceptually) expand search.\n",
    "    \"\"\"\n",
    "    bbox = list(seeds_gdf.total_bounds)\n",
    "    \n",
    "    print(f\"Searching for scenes in {time_range} over {bbox}...\", flush=True)\n",
    "    \n",
    "    scene_ids = []\n",
    "    try:\n",
    "        print(\"  Querying store for scenes...\", flush=True)\n",
    "        # search_data returns an iterator of DataDescriptors\n",
    "        # We use the collection data_id \"sentinel-2-l2a\"\n",
    "        search_result = store.search_data(data_id=\"sentinel-2-l2a\", bbox=bbox, time_range=time_range)\n",
    "        \n",
    "        count = 0\n",
    "        for descriptor in search_result:\n",
    "            if hasattr(descriptor, \"data_id\"):\n",
    "                 scene_ids.append(descriptor.data_id)\n",
    "                 count += 1\n",
    "        \n",
    "        print(f\"  Found {count} scenes via store search.\", flush=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Store search failed: {e}\", flush=True)\n",
    "    \n",
    "    if not scene_ids:\n",
    "        print(\"  WARNING: No scenes found. Please ensure the store supports search or provide manual IDs.\", flush=True)\n",
    "    \n",
    "    results = []\n",
    "    for scene_id in scene_ids:\n",
    "        res = process_scene_native(scene_id, store)\n",
    "        if res:\n",
    "            results.append(res)\n",
    "            \n",
    "            # Check 30% condition\n",
    "            if res['snow_pct'] > 30:\n",
    "                print(f\"  Snow cover > 30%. Marking for expanded search (logic not implemented).\", flush=True)\n",
    "                \n",
    "    return results\n",
    "\n",
    "# Example Usage\n",
    "# time_range = [\"2025-06-01\", \"2025-06-30\"]\n",
    "# results = sentinel_native_algorithm(seeds_gdf, time_range, store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "Compare the native results with the tile-aware Zarr approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
